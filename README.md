# Tweet Hours â€” Twitter Activity Analyzer

A beautiful web application that analyzes Twitter/X accounts to show when they're most active. Visualize activity patterns with heatmaps and charts.

![Python](https://img.shields.io/badge/python-3.11+-blue) ![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green) ![License](https://img.shields.io/badge/license-MIT-1A1A1A)

## âœ¨ Features

- ğŸ”“ **No API key required** â€” uses web scraping
- ğŸ—ºï¸ **Activity heatmap** â€” visualize day Ã— hour patterns
- ğŸ“Š **Distribution charts** â€” hourly and daily breakdowns
- ğŸ”¥ **Peak analysis** â€” discover most active hours and days
- ğŸŒ **Timezone support** â€” convert times to any timezone
- âœ¨ **Beautiful UI** â€” clean, editorial design system

## ğŸš€ Quick Start (Local)

### 1. Install Dependencies

```bash
pip install -r requirements.txt
playwright install chromium
```

### 2. Run the App

```bash
python main.py
```

### 3. Open in Browser

Go to **http://localhost:8000**

---

## ğŸŒ Deploy to Production

### Option 1: Railway (Recommended)

**Step 1:** Push to GitHub
```bash
git init
git add .
git commit -m "Initial commit"
git branch -M main
git remote add origin https://github.com/YOUR_USERNAME/tweet-hours.git
git push -u origin main
```

**Step 2:** Deploy
1. Go to [railway.app](https://railway.app)
2. Click **"New Project"** â†’ **"Deploy from GitHub repo"**
3. Select your repository
4. Railway auto-detects the Dockerfile and deploys
5. Your app is live at `https://your-app.railway.app`

---

### Option 2: Render

1. Push to GitHub (same as above)
2. Go to [render.com](https://render.com)
3. Click **"New"** â†’ **"Web Service"**
4. Connect your GitHub repository
5. Select **"Docker"** as environment
6. Click **"Create Web Service"**

---

### Option 3: Fly.io

```bash
# Install Fly CLI (Windows PowerShell)
iwr https://fly.io/install.ps1 -useb | iex

# Login and deploy
fly auth login
fly launch --name tweet-hours
fly deploy
```

---

## ğŸ“ Project Structure

```
tweet-hours/
â”œâ”€â”€ main.py              # FastAPI backend
â”œâ”€â”€ scraper.py           # Playwright Twitter scraper
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ Dockerfile           # Container config
â”œâ”€â”€ railway.toml         # Railway deployment config
â”œâ”€â”€ render.yaml          # Render deployment config
â”œâ”€â”€ design-system.json   # UI design tokens
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html       # Main page template
â””â”€â”€ static/
    â”œâ”€â”€ css/
    â”‚   â””â”€â”€ style.css    # Editorial Minimal styles
    â””â”€â”€ js/
        â””â”€â”€ app.js       # Frontend JavaScript
```

## ğŸ”§ How It Works

1. **Scraping** â€” Playwright launches headless Chromium to visit public Twitter profiles
2. **Parsing** â€” Extracts tweet timestamps from the DOM
3. **Analysis** â€” Aggregates data by hour and day of week
4. **Visualization** â€” Renders heatmap and charts with Chart.js

## ğŸ¨ Design System

The UI uses the **Editorial Minimal** design system:
- Serif headings (Playfair Display)
- Clean sans-serif body (Inter)
- Warm off-white backgrounds
- Subtle shadows and borders
- Earth-tone heatmap colors

## âš ï¸ Notes

- Only works with **public** Twitter profiles
- Scraping may be slower than API calls (10-20 seconds)
- Twitter may occasionally block requests
- Demo mode available if scraping fails

## ğŸ“„ License

MIT â€” use however you like!

---

Built with FastAPI, Playwright, and Chart.js
